{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26d579f",
   "metadata": {},
   "source": [
    "# Simple Neural Network Music Genre Classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a892c18",
   "metadata": {},
   "source": [
    "This notebook is dedicated to improving the test accuracy of the network presented in:\n",
    "https://www.kaggle.com/code/aasimahmed04/music-genre-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2994ebb4",
   "metadata": {},
   "source": [
    "A variation on the CNN Presented in https://www.kaggle.com/code/farzadnekouei/cifar-10-image-classification-with-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21732dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\420\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, IPython\n",
    "import librosa.display as lplt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from keras import regularizers\n",
    "\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b906a7",
   "metadata": {},
   "source": [
    "### Labels are base on the following mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e088b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ = {\n",
    "    \"blues\"     : 0,\n",
    "    \"classical\" : 1,\n",
    "    \"country\"   : 2,\n",
    "    \"disco\"     : 3,\n",
    "    \"hiphop\"    : 4,\n",
    "    \"jazz\"      : 5,\n",
    "    \"metal\"     : 6,\n",
    "    \"pop\"       : 7,\n",
    "    \"reggae\"    : 8,\n",
    "    \"rock\"      : 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76ff00",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87362db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'features_30_sec.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a27b76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and labels (y)\n",
    "X_ = df.drop(columns=['label','filename','length','rms_var']).values  # Drop the 'label' column to get features\n",
    "y_ = df['label']  # Get the 'label' column for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e08dce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1271fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_[...,np.newaxis]\n",
    "y = np.array([map_[label_] for label_ in y_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6ce0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to appropriate data types\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83fc6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, validation and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50782a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size:  (680, 56, 1)\n",
      "Validation data size:  (170, 56, 1)\n",
      "Test data size:  (150, 56, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data size: \", X_train.shape);\n",
    "print(\"Validation data size: \",X_val.shape);\n",
    "print(\"Test data size: \", X_test.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "768d7420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape_ = (X_train.shape[1], X_train.shape[2])\n",
    "print(input_shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fffa0576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\420\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Initialize a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Set the weight decay value for L2 regularization\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# Define the input shape of the vector (e.g., if vector length is 100, input_shape = (100,))\n",
    "input_shape = (100,)  # Modify based on your vector's length\n",
    "\n",
    "# Add the first 1D convolutional layer with 32 filters of size 3\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay), \n",
    "                 input_shape=input_shape_))\n",
    "# Add batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add the second 1D convolutional layer similar to the first\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add the first max pooling layer with pool size of 2\n",
    "model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "# Add dropout layer with 0.2 dropout rate\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "# Add the third and fourth 1D convolutional layers with 64 filters\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add the second max pooling layer and increase dropout rate to 0.3\n",
    "model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "# Add the fifth and sixth 1D convolutional layers with 128 filters\n",
    "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add the third max pooling layer and increase dropout rate to 0.4\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(rate=0.4))\n",
    "\n",
    "# Flatten the tensor output from the previous layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Layers to classifier\n",
    "\n",
    "model.add(Dense(16,kernel_regularizer=regularizers.l2(0.0005), activation='relu')) \n",
    "model.add(Dropout(0.3))  \n",
    "\n",
    "# Add a fully connected layer with softmax activation function for outputting class probabilities\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0227de29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │           \u001b[38;5;34m3,104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │           \u001b[38;5;34m6,208\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m12,352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m24,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m49,280\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m896\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │          \u001b[38;5;34m14,352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m170\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,090</span> (437.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,090\u001b[0m (437.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,194</span> (434.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,194\u001b[0m (434.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8289c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.1332 - loss: 2.8755 - val_accuracy: 0.2059 - val_loss: 2.2823\n",
      "Epoch 2/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1848 - loss: 2.2831 - val_accuracy: 0.2176 - val_loss: 2.2204\n",
      "Epoch 3/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2602 - loss: 2.1735 - val_accuracy: 0.2294 - val_loss: 2.2202\n",
      "Epoch 4/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2626 - loss: 2.1707 - val_accuracy: 0.2588 - val_loss: 2.1737\n",
      "Epoch 5/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2404 - loss: 2.1610 - val_accuracy: 0.2294 - val_loss: 2.1340\n",
      "Epoch 6/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2214 - loss: 2.1151 - val_accuracy: 0.2882 - val_loss: 2.0858\n",
      "Epoch 7/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2658 - loss: 2.0597 - val_accuracy: 0.1000 - val_loss: 19.6727\n",
      "Epoch 8/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2262 - loss: 2.1146 - val_accuracy: 0.2588 - val_loss: 2.0879\n",
      "Epoch 9/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2259 - loss: 2.0983 - val_accuracy: 0.2706 - val_loss: 2.0296\n",
      "Epoch 10/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2305 - loss: 2.0644 - val_accuracy: 0.2353 - val_loss: 2.0827\n",
      "Epoch 11/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2303 - loss: 2.0674 - val_accuracy: 0.3000 - val_loss: 1.9752\n",
      "Epoch 12/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2451 - loss: 2.0610 - val_accuracy: 0.2765 - val_loss: 2.0390\n",
      "Epoch 13/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2761 - loss: 2.0215 - val_accuracy: 0.3000 - val_loss: 1.9902\n",
      "Epoch 14/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2842 - loss: 2.0072 - val_accuracy: 0.3000 - val_loss: 2.0062\n",
      "Epoch 15/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2609 - loss: 1.9793 - val_accuracy: 0.2529 - val_loss: 2.0254\n",
      "Epoch 16/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2634 - loss: 1.9676 - val_accuracy: 0.3000 - val_loss: 2.0037\n",
      "Epoch 17/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3025 - loss: 1.9577 - val_accuracy: 0.3235 - val_loss: 1.8926\n",
      "Epoch 18/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2325 - loss: 1.9891 - val_accuracy: 0.3235 - val_loss: 1.9304\n",
      "Epoch 19/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2833 - loss: 1.9505 - val_accuracy: 0.3647 - val_loss: 1.8703\n",
      "Epoch 20/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2821 - loss: 1.9574 - val_accuracy: 0.3059 - val_loss: 1.9161\n",
      "Epoch 21/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2761 - loss: 1.9569 - val_accuracy: 0.3235 - val_loss: 1.9005\n",
      "Epoch 22/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2803 - loss: 1.9020 - val_accuracy: 0.3118 - val_loss: 1.8944\n",
      "Epoch 23/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3111 - loss: 1.8762 - val_accuracy: 0.3294 - val_loss: 1.9435\n",
      "Epoch 24/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3152 - loss: 1.8878 - val_accuracy: 0.3353 - val_loss: 1.9022\n",
      "Epoch 25/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3109 - loss: 1.8021 - val_accuracy: 0.3412 - val_loss: 1.8789\n",
      "Epoch 26/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3047 - loss: 1.9264 - val_accuracy: 0.2824 - val_loss: 1.8561\n",
      "Epoch 27/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3334 - loss: 1.8326 - val_accuracy: 0.3059 - val_loss: 1.8525\n",
      "Epoch 28/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3079 - loss: 1.8977 - val_accuracy: 0.3235 - val_loss: 1.9140\n",
      "Epoch 29/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3159 - loss: 1.8310 - val_accuracy: 0.3706 - val_loss: 1.7855\n",
      "Epoch 30/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3060 - loss: 1.8431 - val_accuracy: 0.3882 - val_loss: 1.7950\n",
      "Epoch 31/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3437 - loss: 1.7946 - val_accuracy: 0.3471 - val_loss: 1.8647\n",
      "Epoch 32/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2937 - loss: 1.8465 - val_accuracy: 0.3353 - val_loss: 1.8964\n",
      "Epoch 33/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3297 - loss: 1.8044 - val_accuracy: 0.4059 - val_loss: 1.7949\n",
      "Epoch 34/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3330 - loss: 1.7650 - val_accuracy: 0.3118 - val_loss: 1.9838\n",
      "Epoch 35/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2950 - loss: 1.8609 - val_accuracy: 0.3647 - val_loss: 1.8942\n",
      "Epoch 36/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3220 - loss: 1.8104 - val_accuracy: 0.3647 - val_loss: 1.7714\n",
      "Epoch 37/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3153 - loss: 1.7942 - val_accuracy: 0.3765 - val_loss: 1.7355\n",
      "Epoch 38/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3784 - loss: 1.7689 - val_accuracy: 0.4176 - val_loss: 1.7700\n",
      "Epoch 39/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3370 - loss: 1.7943 - val_accuracy: 0.4000 - val_loss: 1.7161\n",
      "Epoch 40/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3431 - loss: 1.7732 - val_accuracy: 0.3941 - val_loss: 1.7160\n",
      "Epoch 41/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4003 - loss: 1.6584 - val_accuracy: 0.3118 - val_loss: 1.8272\n",
      "Epoch 42/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3411 - loss: 1.8066 - val_accuracy: 0.3588 - val_loss: 1.7529\n",
      "Epoch 43/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3491 - loss: 1.8310 - val_accuracy: 0.3941 - val_loss: 1.7219\n",
      "Epoch 44/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3259 - loss: 1.7376 - val_accuracy: 0.3882 - val_loss: 1.7299\n",
      "Epoch 45/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3928 - loss: 1.7356 - val_accuracy: 0.4118 - val_loss: 1.7071\n",
      "Epoch 46/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3813 - loss: 1.7017 - val_accuracy: 0.4471 - val_loss: 1.6404\n",
      "Epoch 47/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3145 - loss: 1.7496 - val_accuracy: 0.3882 - val_loss: 1.9097\n",
      "Epoch 48/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3528 - loss: 1.7207 - val_accuracy: 0.4118 - val_loss: 1.6627\n",
      "Epoch 49/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3380 - loss: 1.7155 - val_accuracy: 0.4471 - val_loss: 1.6296\n",
      "Epoch 50/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3786 - loss: 1.6614 - val_accuracy: 0.4529 - val_loss: 1.5995\n",
      "Epoch 51/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3425 - loss: 1.7278 - val_accuracy: 0.4588 - val_loss: 1.5799\n",
      "Epoch 52/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4062 - loss: 1.6588 - val_accuracy: 0.4000 - val_loss: 1.6398\n",
      "Epoch 53/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4040 - loss: 1.6306 - val_accuracy: 0.3647 - val_loss: 1.7027\n",
      "Epoch 54/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4016 - loss: 1.6583 - val_accuracy: 0.4294 - val_loss: 1.5770\n",
      "Epoch 55/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3912 - loss: 1.6174 - val_accuracy: 0.3706 - val_loss: 1.6044\n",
      "Epoch 56/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3990 - loss: 1.6441 - val_accuracy: 0.3294 - val_loss: 1.8156\n",
      "Epoch 57/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3839 - loss: 1.6423 - val_accuracy: 0.4000 - val_loss: 1.6497\n",
      "Epoch 58/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3516 - loss: 1.7451 - val_accuracy: 0.3412 - val_loss: 1.8510\n",
      "Epoch 59/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3981 - loss: 1.6349 - val_accuracy: 0.4647 - val_loss: 1.5966\n",
      "Epoch 60/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4254 - loss: 1.6259 - val_accuracy: 0.4059 - val_loss: 1.6042\n",
      "Epoch 61/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4298 - loss: 1.6096 - val_accuracy: 0.3824 - val_loss: 1.5957\n",
      "Epoch 62/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3889 - loss: 1.6704 - val_accuracy: 0.4176 - val_loss: 1.6231\n",
      "Epoch 63/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4085 - loss: 1.6209 - val_accuracy: 0.4235 - val_loss: 1.6286\n",
      "Epoch 64/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4328 - loss: 1.5299 - val_accuracy: 0.3824 - val_loss: 1.7215\n",
      "Epoch 65/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3978 - loss: 1.6453 - val_accuracy: 0.4235 - val_loss: 1.5775\n",
      "Epoch 66/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3916 - loss: 1.6368 - val_accuracy: 0.3882 - val_loss: 1.6323\n",
      "Epoch 67/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4142 - loss: 1.5538 - val_accuracy: 0.4412 - val_loss: 1.5699\n",
      "Epoch 68/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4198 - loss: 1.5790 - val_accuracy: 0.4706 - val_loss: 1.5053\n",
      "Epoch 69/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4001 - loss: 1.5526 - val_accuracy: 0.4706 - val_loss: 1.5041\n",
      "Epoch 70/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4205 - loss: 1.6011 - val_accuracy: 0.4824 - val_loss: 1.5127\n",
      "Epoch 71/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3985 - loss: 1.5891 - val_accuracy: 0.4765 - val_loss: 1.5276\n",
      "Epoch 72/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4140 - loss: 1.5513 - val_accuracy: 0.4235 - val_loss: 1.5901\n",
      "Epoch 73/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4185 - loss: 1.6070 - val_accuracy: 0.4353 - val_loss: 1.5588\n",
      "Epoch 74/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4567 - loss: 1.5396 - val_accuracy: 0.4471 - val_loss: 1.6638\n",
      "Epoch 75/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4338 - loss: 1.5944 - val_accuracy: 0.4647 - val_loss: 1.4996\n",
      "Epoch 76/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4556 - loss: 1.5398 - val_accuracy: 0.3824 - val_loss: 1.6176\n",
      "Epoch 77/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4248 - loss: 1.5565 - val_accuracy: 0.4176 - val_loss: 1.5506\n",
      "Epoch 78/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3968 - loss: 1.5903 - val_accuracy: 0.4588 - val_loss: 1.5115\n",
      "Epoch 79/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4608 - loss: 1.5582 - val_accuracy: 0.4353 - val_loss: 1.5534\n",
      "Epoch 80/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4249 - loss: 1.4881 - val_accuracy: 0.4529 - val_loss: 1.6071\n",
      "Epoch 81/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4440 - loss: 1.5679 - val_accuracy: 0.4588 - val_loss: 1.5605\n",
      "Epoch 82/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4436 - loss: 1.4888 - val_accuracy: 0.4412 - val_loss: 1.5248\n",
      "Epoch 83/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4376 - loss: 1.4651 - val_accuracy: 0.3824 - val_loss: 1.6871\n",
      "Epoch 84/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4253 - loss: 1.4750 - val_accuracy: 0.4471 - val_loss: 1.4887\n",
      "Epoch 85/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4653 - loss: 1.4639 - val_accuracy: 0.4294 - val_loss: 1.5876\n",
      "Epoch 86/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4390 - loss: 1.5310 - val_accuracy: 0.4706 - val_loss: 1.5753\n",
      "Epoch 87/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4093 - loss: 1.5203 - val_accuracy: 0.4765 - val_loss: 1.5200\n",
      "Epoch 88/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4693 - loss: 1.4601 - val_accuracy: 0.4706 - val_loss: 1.5112\n",
      "Epoch 89/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4622 - loss: 1.4939 - val_accuracy: 0.4529 - val_loss: 1.5160\n",
      "Epoch 90/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4616 - loss: 1.4870 - val_accuracy: 0.4059 - val_loss: 1.6017\n",
      "Epoch 91/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4804 - loss: 1.4100 - val_accuracy: 0.4647 - val_loss: 1.5344\n",
      "Epoch 92/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4213 - loss: 1.5123 - val_accuracy: 0.4765 - val_loss: 1.5363\n",
      "Epoch 93/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4908 - loss: 1.4155 - val_accuracy: 0.4647 - val_loss: 1.6178\n",
      "Epoch 94/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4486 - loss: 1.4445 - val_accuracy: 0.4647 - val_loss: 1.5818\n",
      "Epoch 95/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4468 - loss: 1.4769 - val_accuracy: 0.4412 - val_loss: 1.6315\n",
      "Epoch 96/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4860 - loss: 1.4386 - val_accuracy: 0.4529 - val_loss: 1.5795\n",
      "Epoch 97/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4725 - loss: 1.4045 - val_accuracy: 0.4529 - val_loss: 1.5572\n",
      "Epoch 98/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5040 - loss: 1.4603 - val_accuracy: 0.4882 - val_loss: 1.6013\n",
      "Epoch 99/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4953 - loss: 1.3663 - val_accuracy: 0.4647 - val_loss: 1.5710\n",
      "Epoch 100/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4947 - loss: 1.4011 - val_accuracy: 0.5118 - val_loss: 1.4953\n",
      "Epoch 101/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5009 - loss: 1.3680 - val_accuracy: 0.4706 - val_loss: 1.5565\n",
      "Epoch 102/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4918 - loss: 1.3992 - val_accuracy: 0.4882 - val_loss: 1.5502\n",
      "Epoch 103/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4744 - loss: 1.3992 - val_accuracy: 0.4706 - val_loss: 1.6110\n",
      "Epoch 104/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5389 - loss: 1.3924 - val_accuracy: 0.4294 - val_loss: 1.5958\n",
      "Epoch 105/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5369 - loss: 1.3155 - val_accuracy: 0.5000 - val_loss: 1.5413\n",
      "Epoch 106/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5222 - loss: 1.3615 - val_accuracy: 0.4941 - val_loss: 1.6102\n",
      "Epoch 107/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4555 - loss: 1.4197 - val_accuracy: 0.5000 - val_loss: 1.5591\n",
      "Epoch 108/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4960 - loss: 1.3459 - val_accuracy: 0.4706 - val_loss: 1.5861\n",
      "Epoch 109/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4732 - loss: 1.3838 - val_accuracy: 0.4588 - val_loss: 1.6136\n",
      "Epoch 110/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5155 - loss: 1.3971 - val_accuracy: 0.5059 - val_loss: 1.5687\n",
      "Epoch 111/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5088 - loss: 1.3394 - val_accuracy: 0.4941 - val_loss: 1.5495\n",
      "Epoch 112/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4859 - loss: 1.3922 - val_accuracy: 0.4176 - val_loss: 1.6704\n",
      "Epoch 113/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4563 - loss: 1.4446 - val_accuracy: 0.4824 - val_loss: 1.6097\n",
      "Epoch 114/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4895 - loss: 1.3842 - val_accuracy: 0.4647 - val_loss: 1.5816\n",
      "Epoch 115/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5028 - loss: 1.3763 - val_accuracy: 0.4412 - val_loss: 1.6404\n",
      "Epoch 116/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5079 - loss: 1.4163 - val_accuracy: 0.5176 - val_loss: 1.6722\n",
      "Epoch 117/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5378 - loss: 1.3778 - val_accuracy: 0.4706 - val_loss: 1.5913\n",
      "Epoch 118/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5220 - loss: 1.3496 - val_accuracy: 0.4588 - val_loss: 1.5800\n",
      "Epoch 119/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5385 - loss: 1.3168 - val_accuracy: 0.4647 - val_loss: 1.5080\n",
      "Epoch 120/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5304 - loss: 1.3574 - val_accuracy: 0.4941 - val_loss: 1.5160\n",
      "Epoch 121/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4999 - loss: 1.3569 - val_accuracy: 0.4824 - val_loss: 1.5592\n",
      "Epoch 122/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5034 - loss: 1.2881 - val_accuracy: 0.4412 - val_loss: 1.8106\n",
      "Epoch 123/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5003 - loss: 1.4282 - val_accuracy: 0.4706 - val_loss: 1.6085\n",
      "Epoch 124/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5669 - loss: 1.1881 - val_accuracy: 0.4588 - val_loss: 1.5763\n",
      "Epoch 125/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5196 - loss: 1.3420 - val_accuracy: 0.4706 - val_loss: 1.5069\n",
      "Epoch 126/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5441 - loss: 1.3126 - val_accuracy: 0.4824 - val_loss: 1.5450\n",
      "Epoch 127/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4842 - loss: 1.3870 - val_accuracy: 0.4941 - val_loss: 1.4899\n",
      "Epoch 128/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5467 - loss: 1.2713 - val_accuracy: 0.4824 - val_loss: 1.5337\n",
      "Epoch 129/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5199 - loss: 1.2940 - val_accuracy: 0.4471 - val_loss: 1.5655\n",
      "Epoch 130/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5364 - loss: 1.3023 - val_accuracy: 0.5000 - val_loss: 1.4916\n",
      "Epoch 131/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5660 - loss: 1.2766 - val_accuracy: 0.4647 - val_loss: 1.5226\n",
      "Epoch 132/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5659 - loss: 1.2253 - val_accuracy: 0.4765 - val_loss: 1.4861\n",
      "Epoch 133/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5701 - loss: 1.2327 - val_accuracy: 0.4824 - val_loss: 1.5260\n",
      "Epoch 134/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5258 - loss: 1.3149 - val_accuracy: 0.4647 - val_loss: 1.6033\n",
      "Epoch 135/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5438 - loss: 1.2937 - val_accuracy: 0.4235 - val_loss: 1.5985\n",
      "Epoch 136/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5505 - loss: 1.3401 - val_accuracy: 0.4882 - val_loss: 1.5891\n",
      "Epoch 137/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5381 - loss: 1.2879 - val_accuracy: 0.5176 - val_loss: 1.4966\n",
      "Epoch 138/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5399 - loss: 1.2631 - val_accuracy: 0.4941 - val_loss: 1.4832\n",
      "Epoch 139/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5138 - loss: 1.3168 - val_accuracy: 0.4941 - val_loss: 1.4902\n",
      "Epoch 140/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5714 - loss: 1.3217 - val_accuracy: 0.5059 - val_loss: 1.4719\n",
      "Epoch 141/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5622 - loss: 1.2137 - val_accuracy: 0.5176 - val_loss: 1.4649\n",
      "Epoch 142/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5145 - loss: 1.2694 - val_accuracy: 0.5412 - val_loss: 1.4820\n",
      "Epoch 143/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5670 - loss: 1.2353 - val_accuracy: 0.4765 - val_loss: 1.5201\n",
      "Epoch 144/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5252 - loss: 1.2290 - val_accuracy: 0.4882 - val_loss: 1.5060\n",
      "Epoch 145/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5518 - loss: 1.2759 - val_accuracy: 0.5000 - val_loss: 1.4977\n",
      "Epoch 146/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5650 - loss: 1.2205 - val_accuracy: 0.5000 - val_loss: 1.4854\n",
      "Epoch 147/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5470 - loss: 1.2371 - val_accuracy: 0.5176 - val_loss: 1.4750\n",
      "Epoch 148/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5555 - loss: 1.2709 - val_accuracy: 0.4471 - val_loss: 1.5742\n",
      "Epoch 149/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5125 - loss: 1.2608 - val_accuracy: 0.5059 - val_loss: 1.4653\n",
      "Epoch 150/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5305 - loss: 1.2800 - val_accuracy: 0.5118 - val_loss: 1.4688\n",
      "Epoch 151/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6013 - loss: 1.1644 - val_accuracy: 0.5118 - val_loss: 1.4672\n",
      "Epoch 152/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5768 - loss: 1.1983 - val_accuracy: 0.4882 - val_loss: 1.4846\n",
      "Epoch 153/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6064 - loss: 1.1259 - val_accuracy: 0.5059 - val_loss: 1.4623\n",
      "Epoch 154/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5928 - loss: 1.1695 - val_accuracy: 0.5000 - val_loss: 1.4805\n",
      "Epoch 155/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5872 - loss: 1.1717 - val_accuracy: 0.5000 - val_loss: 1.5656\n",
      "Epoch 156/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5503 - loss: 1.1791 - val_accuracy: 0.5118 - val_loss: 1.5865\n",
      "Epoch 157/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5638 - loss: 1.2643 - val_accuracy: 0.5000 - val_loss: 1.5535\n",
      "Epoch 158/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5482 - loss: 1.2490 - val_accuracy: 0.5471 - val_loss: 1.4708\n",
      "Epoch 159/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5619 - loss: 1.2241 - val_accuracy: 0.4882 - val_loss: 1.5461\n",
      "Epoch 160/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5426 - loss: 1.1766 - val_accuracy: 0.5000 - val_loss: 1.5386\n",
      "Epoch 161/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6004 - loss: 1.1570 - val_accuracy: 0.5294 - val_loss: 1.5817\n",
      "Epoch 162/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5885 - loss: 1.2128 - val_accuracy: 0.5000 - val_loss: 1.5079\n",
      "Epoch 163/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5863 - loss: 1.1801 - val_accuracy: 0.4529 - val_loss: 1.6339\n",
      "Epoch 164/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5491 - loss: 1.2153 - val_accuracy: 0.5294 - val_loss: 1.4343\n",
      "Epoch 165/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6387 - loss: 1.1072 - val_accuracy: 0.5176 - val_loss: 1.4697\n",
      "Epoch 166/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5870 - loss: 1.1644 - val_accuracy: 0.5176 - val_loss: 1.5283\n",
      "Epoch 167/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6137 - loss: 1.1028 - val_accuracy: 0.5294 - val_loss: 1.4947\n",
      "Epoch 168/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6164 - loss: 1.1229 - val_accuracy: 0.5000 - val_loss: 1.5471\n",
      "Epoch 169/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6109 - loss: 1.1162 - val_accuracy: 0.5118 - val_loss: 1.6090\n",
      "Epoch 170/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6447 - loss: 1.0541 - val_accuracy: 0.4824 - val_loss: 1.5980\n",
      "Epoch 171/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6504 - loss: 1.1043 - val_accuracy: 0.5059 - val_loss: 1.5559\n",
      "Epoch 172/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5928 - loss: 1.1202 - val_accuracy: 0.5176 - val_loss: 1.5486\n",
      "Epoch 173/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6319 - loss: 1.0603 - val_accuracy: 0.4647 - val_loss: 1.6183\n",
      "Epoch 174/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6157 - loss: 1.0727 - val_accuracy: 0.4706 - val_loss: 1.5309\n",
      "Epoch 175/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5892 - loss: 1.0966 - val_accuracy: 0.5118 - val_loss: 1.5623\n",
      "Epoch 176/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5768 - loss: 1.1700 - val_accuracy: 0.4647 - val_loss: 1.5274\n",
      "Epoch 177/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6012 - loss: 1.1619 - val_accuracy: 0.5176 - val_loss: 1.4500\n",
      "Epoch 178/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6111 - loss: 1.0882 - val_accuracy: 0.4588 - val_loss: 1.6091\n",
      "Epoch 179/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5870 - loss: 1.1163 - val_accuracy: 0.4529 - val_loss: 1.6184\n",
      "Epoch 180/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5978 - loss: 1.1187 - val_accuracy: 0.5235 - val_loss: 1.6216\n",
      "Epoch 181/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6188 - loss: 1.0935 - val_accuracy: 0.5235 - val_loss: 1.5359\n",
      "Epoch 182/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5944 - loss: 1.1545 - val_accuracy: 0.4882 - val_loss: 1.4689\n",
      "Epoch 183/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6044 - loss: 1.1512 - val_accuracy: 0.4824 - val_loss: 1.5253\n",
      "Epoch 184/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6312 - loss: 1.1015 - val_accuracy: 0.5000 - val_loss: 1.5141\n",
      "Epoch 185/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5878 - loss: 1.1476 - val_accuracy: 0.4647 - val_loss: 1.5850\n",
      "Epoch 186/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6449 - loss: 1.0419 - val_accuracy: 0.4824 - val_loss: 1.5916\n",
      "Epoch 187/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6265 - loss: 1.0497 - val_accuracy: 0.5118 - val_loss: 1.5424\n",
      "Epoch 188/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6181 - loss: 1.0777 - val_accuracy: 0.5294 - val_loss: 1.6067\n",
      "Epoch 189/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6512 - loss: 1.1243 - val_accuracy: 0.4706 - val_loss: 1.6793\n",
      "Epoch 190/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6316 - loss: 1.0505 - val_accuracy: 0.5353 - val_loss: 1.5858\n",
      "Epoch 191/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6382 - loss: 1.0588 - val_accuracy: 0.5294 - val_loss: 1.5838\n",
      "Epoch 192/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6221 - loss: 1.0931 - val_accuracy: 0.5412 - val_loss: 1.5291\n",
      "Epoch 193/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6078 - loss: 1.0742 - val_accuracy: 0.5353 - val_loss: 1.5818\n",
      "Epoch 194/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6499 - loss: 0.9831 - val_accuracy: 0.5000 - val_loss: 1.6202\n",
      "Epoch 195/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6421 - loss: 1.0353 - val_accuracy: 0.5118 - val_loss: 1.6411\n",
      "Epoch 196/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6676 - loss: 0.9907 - val_accuracy: 0.5059 - val_loss: 1.5904\n",
      "Epoch 197/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6836 - loss: 1.0026 - val_accuracy: 0.5176 - val_loss: 1.5204\n",
      "Epoch 198/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6601 - loss: 1.0037 - val_accuracy: 0.5000 - val_loss: 1.6500\n",
      "Epoch 199/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6222 - loss: 1.0460 - val_accuracy: 0.5235 - val_loss: 1.6604\n",
      "Epoch 200/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6481 - loss: 1.0406 - val_accuracy: 0.4706 - val_loss: 1.7174\n",
      "Epoch 201/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6139 - loss: 1.0747 - val_accuracy: 0.5000 - val_loss: 1.6195\n",
      "Epoch 202/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6097 - loss: 1.0412 - val_accuracy: 0.4941 - val_loss: 1.5869\n",
      "Epoch 203/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6358 - loss: 1.0678 - val_accuracy: 0.4824 - val_loss: 1.6414\n",
      "Epoch 204/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6538 - loss: 0.9890 - val_accuracy: 0.5176 - val_loss: 1.6287\n",
      "Epoch 205/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6376 - loss: 1.0645 - val_accuracy: 0.5000 - val_loss: 1.6019\n",
      "Epoch 206/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6748 - loss: 0.9164 - val_accuracy: 0.5118 - val_loss: 1.6727\n",
      "Epoch 207/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6572 - loss: 0.9766 - val_accuracy: 0.4706 - val_loss: 1.6353\n",
      "Epoch 208/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6702 - loss: 0.9251 - val_accuracy: 0.4706 - val_loss: 1.6997\n",
      "Epoch 209/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6632 - loss: 0.9544 - val_accuracy: 0.4941 - val_loss: 1.7200\n",
      "Epoch 210/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6362 - loss: 1.0708 - val_accuracy: 0.4824 - val_loss: 1.6561\n",
      "Epoch 211/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6592 - loss: 1.0287 - val_accuracy: 0.4706 - val_loss: 1.6720\n",
      "Epoch 212/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5887 - loss: 1.1360 - val_accuracy: 0.4824 - val_loss: 1.6064\n",
      "Epoch 213/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6475 - loss: 0.9839 - val_accuracy: 0.4588 - val_loss: 1.6280\n",
      "Epoch 214/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6564 - loss: 0.9576 - val_accuracy: 0.4882 - val_loss: 1.7507\n",
      "Epoch 215/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6355 - loss: 1.1148 - val_accuracy: 0.4765 - val_loss: 1.6559\n",
      "Epoch 216/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6429 - loss: 0.9908 - val_accuracy: 0.4765 - val_loss: 1.5925\n",
      "Epoch 217/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6574 - loss: 0.9120 - val_accuracy: 0.4941 - val_loss: 1.6598\n",
      "Epoch 218/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6204 - loss: 1.0084 - val_accuracy: 0.5059 - val_loss: 1.6360\n",
      "Epoch 219/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6683 - loss: 0.9214 - val_accuracy: 0.5000 - val_loss: 1.5951\n",
      "Epoch 220/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6658 - loss: 0.9672 - val_accuracy: 0.4941 - val_loss: 1.5726\n",
      "Epoch 221/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6382 - loss: 1.0311 - val_accuracy: 0.5294 - val_loss: 1.5764\n",
      "Epoch 222/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6761 - loss: 0.9488 - val_accuracy: 0.5118 - val_loss: 1.5027\n",
      "Epoch 223/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6240 - loss: 1.0109 - val_accuracy: 0.4882 - val_loss: 1.5795\n",
      "Epoch 224/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6566 - loss: 0.9674 - val_accuracy: 0.5176 - val_loss: 1.5541\n",
      "Epoch 225/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6860 - loss: 0.9598 - val_accuracy: 0.5059 - val_loss: 1.5662\n",
      "Epoch 226/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6494 - loss: 0.9562 - val_accuracy: 0.5176 - val_loss: 1.6205\n",
      "Epoch 227/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6415 - loss: 0.9394 - val_accuracy: 0.4824 - val_loss: 1.6143\n",
      "Epoch 228/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6679 - loss: 0.9643 - val_accuracy: 0.4824 - val_loss: 1.5944\n",
      "Epoch 229/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6848 - loss: 0.9613 - val_accuracy: 0.4647 - val_loss: 1.6745\n",
      "Epoch 230/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6420 - loss: 0.9799 - val_accuracy: 0.4882 - val_loss: 1.6469\n",
      "Epoch 231/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6772 - loss: 0.9349 - val_accuracy: 0.5118 - val_loss: 1.5827\n",
      "Epoch 232/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6628 - loss: 0.9781 - val_accuracy: 0.4824 - val_loss: 1.6466\n",
      "Epoch 233/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6545 - loss: 1.0053 - val_accuracy: 0.4765 - val_loss: 1.6489\n",
      "Epoch 234/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6619 - loss: 0.9438 - val_accuracy: 0.5000 - val_loss: 1.5835\n",
      "Epoch 235/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6916 - loss: 0.8957 - val_accuracy: 0.5118 - val_loss: 1.6771\n",
      "Epoch 236/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6855 - loss: 1.0194 - val_accuracy: 0.4882 - val_loss: 1.5944\n",
      "Epoch 237/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6408 - loss: 0.9611 - val_accuracy: 0.5118 - val_loss: 1.6356\n",
      "Epoch 238/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6723 - loss: 0.9345 - val_accuracy: 0.5118 - val_loss: 1.7148\n",
      "Epoch 239/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6740 - loss: 0.9329 - val_accuracy: 0.4882 - val_loss: 1.7355\n",
      "Epoch 240/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6746 - loss: 0.9596 - val_accuracy: 0.4941 - val_loss: 1.6893\n",
      "Epoch 241/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6499 - loss: 0.9755 - val_accuracy: 0.4882 - val_loss: 1.7198\n",
      "Epoch 242/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7056 - loss: 0.8803 - val_accuracy: 0.5176 - val_loss: 1.7312\n",
      "Epoch 243/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7003 - loss: 0.9136 - val_accuracy: 0.4941 - val_loss: 1.7360\n",
      "Epoch 244/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6628 - loss: 0.9216 - val_accuracy: 0.4941 - val_loss: 1.7316\n",
      "Epoch 245/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6811 - loss: 0.8989 - val_accuracy: 0.5059 - val_loss: 1.6367\n",
      "Epoch 246/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6967 - loss: 0.9204 - val_accuracy: 0.5118 - val_loss: 1.6628\n",
      "Epoch 247/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6620 - loss: 0.9323 - val_accuracy: 0.4647 - val_loss: 1.6358\n",
      "Epoch 248/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7143 - loss: 0.8671 - val_accuracy: 0.5000 - val_loss: 1.6414\n",
      "Epoch 249/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6646 - loss: 0.9149 - val_accuracy: 0.5118 - val_loss: 1.6320\n",
      "Epoch 250/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7118 - loss: 0.8753 - val_accuracy: 0.5353 - val_loss: 1.6932\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6774 - loss: 0.9809 - val_accuracy: 0.4941 - val_loss: 1.7027\n",
      "Epoch 252/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6518 - loss: 0.9724 - val_accuracy: 0.5000 - val_loss: 1.6829\n",
      "Epoch 253/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6937 - loss: 0.9271 - val_accuracy: 0.4882 - val_loss: 1.6791\n",
      "Epoch 254/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7249 - loss: 0.8582 - val_accuracy: 0.4941 - val_loss: 1.7100\n",
      "Epoch 255/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6869 - loss: 0.8938 - val_accuracy: 0.5353 - val_loss: 1.6456\n",
      "Epoch 256/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6862 - loss: 0.8869 - val_accuracy: 0.5000 - val_loss: 1.6739\n",
      "Epoch 257/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7055 - loss: 0.9158 - val_accuracy: 0.5176 - val_loss: 1.6954\n",
      "Epoch 258/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6755 - loss: 0.9093 - val_accuracy: 0.5059 - val_loss: 1.6669\n",
      "Epoch 259/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6578 - loss: 0.9603 - val_accuracy: 0.4941 - val_loss: 1.7593\n",
      "Epoch 260/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6870 - loss: 0.9103 - val_accuracy: 0.4882 - val_loss: 1.7117\n",
      "Epoch 261/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6658 - loss: 0.9402 - val_accuracy: 0.5059 - val_loss: 1.7183\n",
      "Epoch 262/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6870 - loss: 0.9676 - val_accuracy: 0.4647 - val_loss: 1.7771\n",
      "Epoch 263/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6501 - loss: 0.9459 - val_accuracy: 0.5059 - val_loss: 1.8222\n",
      "Epoch 264/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7119 - loss: 0.8883 - val_accuracy: 0.4882 - val_loss: 1.7374\n",
      "Epoch 265/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6883 - loss: 0.8475 - val_accuracy: 0.4941 - val_loss: 1.7074\n",
      "Epoch 266/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7302 - loss: 0.8486 - val_accuracy: 0.5118 - val_loss: 1.7486\n",
      "Epoch 267/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6956 - loss: 0.9285 - val_accuracy: 0.5176 - val_loss: 1.7084\n",
      "Epoch 268/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6859 - loss: 0.9659 - val_accuracy: 0.4706 - val_loss: 1.7652\n",
      "Epoch 269/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7110 - loss: 0.8766 - val_accuracy: 0.4882 - val_loss: 1.7006\n",
      "Epoch 270/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7037 - loss: 0.8737 - val_accuracy: 0.4765 - val_loss: 1.7033\n",
      "Epoch 271/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7062 - loss: 0.8454 - val_accuracy: 0.5294 - val_loss: 1.7318\n",
      "Epoch 272/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6991 - loss: 0.8430 - val_accuracy: 0.5353 - val_loss: 1.7299\n",
      "Epoch 273/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7029 - loss: 0.8924 - val_accuracy: 0.5176 - val_loss: 1.6852\n",
      "Epoch 274/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7125 - loss: 0.8148 - val_accuracy: 0.5235 - val_loss: 1.7428\n",
      "Epoch 275/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7192 - loss: 0.8879 - val_accuracy: 0.5000 - val_loss: 1.6612\n",
      "Epoch 276/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7568 - loss: 0.7789 - val_accuracy: 0.5176 - val_loss: 1.6554\n",
      "Epoch 277/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7384 - loss: 0.7746 - val_accuracy: 0.5118 - val_loss: 1.7646\n",
      "Epoch 278/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7094 - loss: 0.8374 - val_accuracy: 0.5059 - val_loss: 1.7269\n",
      "Epoch 279/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6804 - loss: 0.9168 - val_accuracy: 0.5000 - val_loss: 1.7281\n",
      "Epoch 280/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7604 - loss: 0.7914 - val_accuracy: 0.4941 - val_loss: 1.7415\n",
      "Epoch 281/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7271 - loss: 0.8386 - val_accuracy: 0.5294 - val_loss: 1.6865\n",
      "Epoch 282/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7236 - loss: 0.8353 - val_accuracy: 0.5235 - val_loss: 1.7562\n",
      "Epoch 283/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7331 - loss: 0.8529 - val_accuracy: 0.5059 - val_loss: 1.7914\n",
      "Epoch 284/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6838 - loss: 0.8720 - val_accuracy: 0.4882 - val_loss: 1.7302\n",
      "Epoch 285/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7229 - loss: 0.8213 - val_accuracy: 0.4882 - val_loss: 1.7912\n",
      "Epoch 286/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7318 - loss: 0.8141 - val_accuracy: 0.5529 - val_loss: 1.7092\n",
      "Epoch 287/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6946 - loss: 0.8540 - val_accuracy: 0.4824 - val_loss: 1.7815\n",
      "Epoch 288/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6763 - loss: 0.9027 - val_accuracy: 0.5176 - val_loss: 1.7367\n",
      "Epoch 289/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7178 - loss: 0.8414 - val_accuracy: 0.5353 - val_loss: 1.7574\n",
      "Epoch 290/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7353 - loss: 0.8068 - val_accuracy: 0.4706 - val_loss: 1.8784\n",
      "Epoch 291/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7202 - loss: 0.7710 - val_accuracy: 0.4824 - val_loss: 1.9117\n",
      "Epoch 292/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7071 - loss: 0.8740 - val_accuracy: 0.4824 - val_loss: 1.8303\n",
      "Epoch 293/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7219 - loss: 0.8002 - val_accuracy: 0.5000 - val_loss: 1.7843\n",
      "Epoch 294/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7582 - loss: 0.8012 - val_accuracy: 0.4706 - val_loss: 1.7886\n",
      "Epoch 295/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6872 - loss: 0.8924 - val_accuracy: 0.5059 - val_loss: 1.7947\n",
      "Epoch 296/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7555 - loss: 0.7957 - val_accuracy: 0.5176 - val_loss: 1.7211\n",
      "Epoch 297/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7121 - loss: 0.8333 - val_accuracy: 0.5118 - val_loss: 1.7201\n",
      "Epoch 298/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7609 - loss: 0.7483 - val_accuracy: 0.4765 - val_loss: 1.8712\n",
      "Epoch 299/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7084 - loss: 0.8440 - val_accuracy: 0.4706 - val_loss: 1.8188\n",
      "Epoch 300/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7195 - loss: 0.7994 - val_accuracy: 0.5118 - val_loss: 1.7326\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=300, validation_data=(X_val, y_val), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8872adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predict = np.argmax(model.predict(X_test),axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c225bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 52.00 %\n"
     ]
    }
   ],
   "source": [
    "acc = np.mean(y_predict == y_test)*100\n",
    "print(\"test accuracy = %.2f\"%acc, \"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22beb3c",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b55b5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b8590e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf995f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
