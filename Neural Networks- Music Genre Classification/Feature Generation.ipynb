{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating 2 different Features csv files from GTZAN Dataset\n",
    "\n",
    "## Import libraries and create empty dictionary\n",
    "\n",
    "The structure is the same as the original csv files (features_30_sec.csv)\n",
    "\n",
    "Each wav file will create one row. The first approach is un segment per wav file.\n",
    "Later on I will increase this variable to 10, so that samples will be splitted into 3-seconds-long samples (same as features_3_sec.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T12:32:50.680812Z",
     "iopub.status.busy": "2023-09-28T12:32:50.679936Z",
     "iopub.status.idle": "2023-09-28T12:32:50.720403Z",
     "shell.execute_reply": "2023-09-28T12:32:50.719537Z",
     "shell.execute_reply.started": "2023-09-28T12:32:50.680755Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T15:12:24.903605Z",
     "iopub.status.busy": "2023-09-20T15:12:24.903227Z",
     "iopub.status.idle": "2023-09-20T15:12:24.918229Z",
     "shell.execute_reply": "2023-09-20T15:12:24.91672Z",
     "shell.execute_reply.started": "2023-09-20T15:12:24.903576Z"
    }
   },
   "outputs": [],
   "source": [
    "num_segment=1\n",
    "num_mfcc=20\n",
    "sample_rate=22050\n",
    "n_fft=2048\n",
    "hop_length=512\n",
    "my_csv={\"filename\":[], \"chroma_stft_mean\": [], \"chroma_stft_var\": [], \"rms_mean\": [], \"rms_var\": [], \"spectral_centroid_mean\": [],\n",
    "        \"spectral_centroid_var\": [], \"spectral_bandwidth_mean\": [], \"spectral_bandwidth_var\": [], \"rolloff_mean\": [], \"rolloff_var\": [],\n",
    "        \"zero_crossing_rate_mean\": [], \"zero_crossing_rate_var\": [], \"harmony_mean\": [], \"harmony_var\": [], \"perceptr_mean\": [],\n",
    "        \"perceptr_var\": [], \"tempo\": [], \"mfcc1_mean\": [], \"mfcc1_var\" : [], \"mfcc2_mean\" : [], \"mfcc2_var\" : [],\n",
    "        \"mfcc3_mean\" : [], \"mfcc3_var\" : [], \"mfcc4_mean\" : [], \"mfcc4_var\" : [], \"mfcc5_mean\" : [], \n",
    "        \"mfcc5_var\" : [], \"mfcc6_mean\" : [], \"mfcc6_var\" : [], \"mfcc7_mean\" : [], \"mfcc7_var\" : [],\n",
    "        \"mfcc8_mean\" : [], \"mfcc8_var\" : [], \"mfcc9_mean\" : [], \"mfcc9_var\" : [], \"mfcc10_mean\" : [], \n",
    "        \"mfcc10_var\" : [], \"mfcc11_mean\" : [], \"mfcc11_var\" : [], \"mfcc12_mean\" : [], \"mfcc12_var\" : [], \n",
    "        \"mfcc13_mean\" : [], \"mfcc13_var\" : [], \"mfcc14_mean\" : [], \"mfcc14_var\" : [], \"mfcc15_mean\" : [], \n",
    "        \"mfcc15_var\" : [], \"mfcc16_mean\" : [], \"mfcc16_var\" : [], \"mfcc17_mean\" : [], \"mfcc17_var\" : [], \n",
    "        \"mfcc18_mean\" : [], \"mfcc18_var\" : [], \"mfcc19_mean\" : [], \"mfcc19_var\" : [], \"mfcc20_mean\" : [], \n",
    "        \"mfcc20_var\":[], \"label\":[]}\n",
    "my_3_csv=my_csv.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create filenames list and genre list, reading Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T15:12:27.650737Z",
     "iopub.status.busy": "2023-09-20T15:12:27.650311Z",
     "iopub.status.idle": "2023-09-20T15:12:27.672068Z",
     "shell.execute_reply": "2023-09-20T15:12:27.670404Z",
     "shell.execute_reply.started": "2023-09-20T15:12:27.650706Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz']\n"
     ]
    }
   ],
   "source": [
    "dataset_path= r\"C:/Users/420/Desktop/NeuralNetworksFinalProject/genres_original\"\n",
    "audio_files = glob(dataset_path + \"/*/*\",recursive=True)\n",
    "genre_ = glob(dataset_path + \"/*\",recursive=True)\n",
    "n_genres=len(genre)\n",
    "genre_=[genre_[x].split('/')[-1][16:] for x in range(n_genres)]\n",
    "print(genre_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features from each file and add values to dictionary\n",
    "\n",
    "This code uses one segment per file.\n",
    "The process is slow. For every genre and file, a new message is shown.\n",
    "Features are extracted from the complete sample of each file. Later we will divide each 30-seconds-sample into 10 3-seconds-samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing blues...\n",
      "genres_original\\blues\\blues.00000.wav\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m my_csv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrms_var\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(RMSEn\u001b[38;5;241m.\u001b[39mvar())\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#Spectral Centroid\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m spec_cent\u001b[38;5;241m=\u001b[39mlibrosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mspectral_centroid(y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m     28\u001b[0m my_csv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspectral_centroid_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(spec_cent\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     29\u001b[0m my_csv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspectral_centroid_var\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(spec_cent\u001b[38;5;241m.\u001b[39mvar())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\feature\\spectral.py:185\u001b[0m, in \u001b[0;36mspectral_centroid\u001b[1;34m(y, sr, S, n_fft, hop_length, freq, win_length, window, center, pad_mode)\u001b[0m\n\u001b[0;32m    182\u001b[0m     freq \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mexpand_to(freq, ndim\u001b[38;5;241m=\u001b[39mS\u001b[38;5;241m.\u001b[39mndim, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Column-normalize S\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m centroid: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m    186\u001b[0m     freq \u001b[38;5;241m*\u001b[39m util\u001b[38;5;241m.\u001b[39mnormalize(S, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    187\u001b[0m )\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m centroid\n",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = -1;\n",
    "genre = \"blues\"\n",
    "for counter,f in enumerate(sorted(audio_files)):\n",
    "    if (counter%100 == 0):\n",
    "        i = i+1;\n",
    "        print(\"Processing \" + genre + \"...\")\n",
    "    genre = genre_[i]\n",
    "        \n",
    "    fname=f.split('/')[-1]\n",
    "    try:\n",
    "        y, sr = librosa.load(f, sr=sample_rate)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    #Chromagram\n",
    "    chroma_hop_length = 512 #5000?\n",
    "    chromagram = librosa.feature.chroma_stft(y=y, sr=sample_rate, hop_length=chroma_hop_length)\n",
    "    my_csv[\"chroma_stft_mean\"].append(chromagram.mean())\n",
    "    my_csv[\"chroma_stft_var\"].append(chromagram.var())\n",
    "    \n",
    "    #Root Mean Square Energy\n",
    "    RMSEn= librosa.feature.rms(y=y)\n",
    "    my_csv[\"rms_mean\"].append(RMSEn.mean())\n",
    "    my_csv[\"rms_var\"].append(RMSEn.var())\n",
    "    \n",
    "    #Spectral Centroid\n",
    "    spec_cent=librosa.feature.spectral_centroid(y=y)\n",
    "    my_csv[\"spectral_centroid_mean\"].append(spec_cent.mean())\n",
    "    my_csv[\"spectral_centroid_var\"].append(spec_cent.var())\n",
    "    \n",
    "    #Spectral Bandwith\n",
    "    spec_band=librosa.feature.spectral_bandwidth(y=y,sr=sample_rate)\n",
    "    my_csv[\"spectral_bandwidth_mean\"].append(spec_band.mean())\n",
    "    my_csv[\"spectral_bandwidth_var\"].append(spec_band.var())\n",
    "\n",
    "    #Rolloff\n",
    "    spec_roll=librosa.feature.spectral_rolloff(y=y,sr=sample_rate)\n",
    "    my_csv[\"rolloff_mean\"].append(spec_roll.mean())\n",
    "    my_csv[\"rolloff_var\"].append(spec_roll.var())\n",
    "    \n",
    "    #Zero Crossing Rate\n",
    "    zero_crossing=librosa.feature.zero_crossing_rate(y=y)\n",
    "    my_csv[\"zero_crossing_rate_mean\"].append(zero_crossing.mean())\n",
    "    my_csv[\"zero_crossing_rate_var\"].append(zero_crossing.var())\n",
    "    \n",
    "    #Harmonics and Perceptrual \n",
    "    harmony, perceptr = librosa.effects.hpss(y=y)\n",
    "    my_csv[\"harmony_mean\"].append(harmony.mean())\n",
    "    my_csv[\"harmony_var\"].append(harmony.var())\n",
    "    my_csv[\"perceptr_mean\"].append(perceptr.mean())\n",
    "    my_csv[\"perceptr_var\"].append(perceptr.var())\n",
    "    \n",
    "    #Tempo\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr = sr)\n",
    "    my_csv[\"tempo\"].append(tempo)\n",
    "\n",
    "    #MEDIAS Y VARIANZAS DE LOS MFCC\n",
    "    mfcc=librosa.feature.mfcc(y=y,sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfcc=mfcc.T\n",
    "    #algunos archivos difieren en len(mfcc) por 1. No cambia nada, saco el if que los descarta\n",
    "    my_csv[\"filename\"].append(fname)\n",
    "    my_csv[\"label\"].append(genre)\n",
    "    for x in range(20):\n",
    "        feat1 = \"mfcc\" + str(x+1) + \"_mean\"\n",
    "        feat2 = \"mfcc\" + str(x+1) + \"_var\"\n",
    "        my_csv[feat1].append(mfcc[:,x].mean())\n",
    "        my_csv[feat2].append(mfcc[:,x].var())\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe from dictionary and save csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-20T15:12:18.294454Z",
     "iopub.status.idle": "2023-09-20T15:12:18.294909Z",
     "shell.execute_reply": "2023-09-20T15:12:18.294722Z",
     "shell.execute_reply.started": "2023-09-20T15:12:18.294702Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(my_csv)\n",
    "df.to_csv('myfeatures.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended csv file: 10 segments per wav file\n",
    "\n",
    "To create the same csv features-file, but with 3-seconds-samples (10 segments per file), I used this code.\n",
    "\n",
    "It creates 10 rows for each sample-song, like the original features_3_sec.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T12:37:33.834557Z",
     "iopub.status.busy": "2023-09-28T12:37:33.834177Z",
     "iopub.status.idle": "2023-09-28T12:37:34.366526Z",
     "shell.execute_reply": "2023-09-28T12:37:34.365481Z",
     "shell.execute_reply.started": "2023-09-28T12:37:33.834526Z"
    }
   },
   "outputs": [],
   "source": [
    "num_mfcc=20\n",
    "sample_rate=22050\n",
    "n_fft=2048\n",
    "hop_length=512\n",
    "num_segment=10\n",
    "samples_per_segment = int(sample_rate*30/num_segment)\n",
    "dataset_path=r\"C:/Users/420/Desktop/NeuralNetworksFinalProject/genres_original\"\n",
    "audio_files = glob(dataset_path + \"/*/*\")\n",
    "genre_ = glob(dataset_path + \"/*\")\n",
    "n_genres=len(genre_)\n",
    "genre_=[genre_[x].split('/')[-1][16:] for x in range(n_genres)]\n",
    "print(genre_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_segment=10\n",
    "samples_per_segment = int(sample_rate*30/num_segment)\n",
    "\n",
    "\n",
    "i = -1;\n",
    "genre = \"blues\"\n",
    "for counter,f in enumerate(sorted(audio_files)):\n",
    "    if (counter%100 == 0):\n",
    "        i = i+1;\n",
    "        print(\"Processing \" + genre + \"...\")\n",
    "    genre = genre_[i]\n",
    "        \n",
    "    fname=f.split('/')[-1]\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(f, sr=sample_rate)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    for n in range(num_segment):\n",
    "        #print(\"segment = \",n+1)\n",
    "        y_seg = y[samples_per_segment*n: samples_per_segment*(n+1)]\n",
    "        #Chromagram\n",
    "        chroma_hop_length = 512\n",
    "        chromagram = librosa.feature.chroma_stft(y=y_seg, sr=sample_rate, hop_length=chroma_hop_length)\n",
    "        my_3_csv[\"chroma_stft_mean\"].append(chromagram.mean())\n",
    "        my_3_csv[\"chroma_stft_var\"].append(chromagram.var())\n",
    "\n",
    "        #Root Mean Square Energy\n",
    "        RMSEn= librosa.feature.rms(y=y_seg)\n",
    "        my_3_csv[\"rms_mean\"].append(RMSEn.mean())\n",
    "        my_3_csv[\"rms_var\"].append(RMSEn.var())\n",
    "\n",
    "        #Spectral Centroid\n",
    "        spec_cent=librosa.feature.spectral_centroid(y=y_seg)\n",
    "        my_3_csv[\"spectral_centroid_mean\"].append(spec_cent.mean())\n",
    "        my_3_csv[\"spectral_centroid_var\"].append(spec_cent.var())\n",
    "\n",
    "        #Spectral Bandwith\n",
    "        spec_band=librosa.feature.spectral_bandwidth(y=y_seg,sr=sample_rate)\n",
    "        my_3_csv[\"spectral_bandwidth_mean\"].append(spec_band.mean())\n",
    "        my_3_csv[\"spectral_bandwidth_var\"].append(spec_band.var())\n",
    "\n",
    "        #Rolloff\n",
    "        spec_roll=librosa.feature.spectral_rolloff(y=y_seg,sr=sample_rate)\n",
    "        my_3_csv[\"rolloff_mean\"].append(spec_roll.mean())\n",
    "        my_3_csv[\"rolloff_var\"].append(spec_roll.var())\n",
    "\n",
    "        #Zero Crossing Rate\n",
    "        zero_crossing=librosa.feature.zero_crossing_rate(y=y_seg)\n",
    "        my_3_csv[\"zero_crossing_rate_mean\"].append(zero_crossing.mean())\n",
    "        my_3_csv[\"zero_crossing_rate_var\"].append(zero_crossing.var())\n",
    "\n",
    "        #Harmonics and Perceptrual \n",
    "        harmony, perceptr = librosa.effects.hpss(y=y_seg)\n",
    "        my_3_csv[\"harmony_mean\"].append(harmony.mean())\n",
    "        my_3_csv[\"harmony_var\"].append(harmony.var())\n",
    "        my_3_csv[\"perceptr_mean\"].append(perceptr.mean())\n",
    "        my_3_csv[\"perceptr_var\"].append(perceptr.var())\n",
    "\n",
    "        #Tempo\n",
    "        tempo, _ = librosa.beat.beat_track(y=y_seg, sr=sample_rate)\n",
    "        my_3_csv[\"tempo\"].append(tempo)\n",
    "\n",
    "        #MEDIAS Y VARIANZAS DE LOS MFCC\n",
    "        mfcc=librosa.feature.mfcc(y=y_seg,sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "        mfcc=mfcc.T\n",
    "        #algunos archivos difieren en len(mfcc) por 1. No cambia nada, saco el if que los descarta\n",
    "        fseg_name='.'.join(fname.split('.')[:2])+f'.{n}.wav'\n",
    "        my_3_csv[\"filename\"].append(fseg_name)\n",
    "        my_3_csv[\"label\"].append(genre)\n",
    "        for x in range(20):\n",
    "            feat1 = \"mfcc\" + str(x+1) + \"_mean\"\n",
    "            feat2 = \"mfcc\" + str(x+1) + \"_var\"\n",
    "            my_3_csv[feat1].append(mfcc[:,x].mean())\n",
    "            my_3_csv[feat2].append(mfcc[:,x].var())\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe from dictionary and save csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-20T15:12:18.298582Z",
     "iopub.status.idle": "2023-09-20T15:12:18.299091Z",
     "shell.execute_reply": "2023-09-20T15:12:18.298868Z",
     "shell.execute_reply.started": "2023-09-20T15:12:18.298838Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(my_3_csv)\n",
    "df.to_csv('myfeatures_3_sec.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 568973,
     "sourceId": 1032238,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30527,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
